import streamlit as st
import os
import json
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import WebBaseLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import google.generativeai as genai  # ‡πÄ‡∏û‡∏¥‡πà‡∏° Gemini import

# Set page config
st.set_page_config(page_title="‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà AI", layout="wide")

# Load environment variables
load_dotenv()

# Retrieve the Gemini API key from the environment variable
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Check if the API key is loaded
if not GEMINI_API_KEY:
    st.error("API key not found. Please set GEMINI_API_KEY in your .env file.")

# Sidebar
with st.sidebar:
    st.title("üèîÔ∏è ‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà AI")
    st.markdown("---")
    st.markdown("‡∏£‡∏∞‡∏ö‡∏ö AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß")
    st.markdown("‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ RAG ‡πÅ‡∏•‡∏∞ Gemini LLM API")
    st.markdown("---")
    
    # Add some useful information in sidebar
    st.subheader("‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö")
    st.markdown("""
    - ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á
    - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠
    - ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ AI
    """)

# Main content
st.title("üå¥ ‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏±‡∏ö AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß")
st.markdown("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢!")

# Initialize session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Initialize session state for vector database
if "vectordb" not in st.session_state:
    st.session_state.vectordb = None

# Function to initialize vector database
@st.cache_resource
def initialize_vectordb():
    try:
        # List of popular Chiang Mai tourism websites
        urls = [
            "https://www.tourismthailand.org/Destinations/Provinces/Chiang-Mai/217",
            "https://www.tourismthailand.org/Search-result/attraction?destination_id=101&sort_by=datetime_updated_desc&page=1&perpage=15&menu=attraction",
            "https://www.lonelyplanet.com/thailand/chiang-mai-province/chiang-mai", 
            "https://wikitravel.org/en/Chiang_Mai",
            "https://www.tripadvisor.com/Tourism-g293917-Chiang_Mai-Vacations.html",
            "https://www.wongnai.com/trips/travel-at-chiangmai",
        
        ]
        
        # Load documents from URLs
        documents = []
        for url in urls:
            loader = WebBaseLoader(url)
            data = loader.load()
            documents.extend(data)
            
        # Split documents into chunks
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_documents(documents)
        
        # Initialize embeddings model
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        
        # Create vector database
        vectordb = FAISS.from_documents(chunks, embeddings)
        
        return vectordb
    
    except Exception as e:
        st.error(f"Error initializing vector database: {str(e)}")
        return None

# Load vector database if not already loaded
if st.session_state.vectordb is None:
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà..."):
        st.session_state.vectordb = initialize_vectordb()

# Function to generate response using Gemini API with RAG

def generate_response(query, context, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        # ‡∏£‡∏ß‡∏° context ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö prompt
        prompt = f"""{context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡πÑ‡∏Å‡∏î‡πå‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô system prompt ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á\n\nSystem Prompt:\n‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ \"‡∏°‡∏ó‡∏£.‡∏•‡πâ‡∏≤‡∏ô‡∏ô‡∏≤ ‡πÑ‡∏Å‡∏î‡πå‡πÄ‡∏à‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\" (RMUTL Guide Chiang Mai) ‡πÄ‡∏õ‡πá‡∏ô Chatbot ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏£‡∏á‡∏ö‡∏±‡∏ô‡∏î‡∏≤‡∏•‡πÉ‡∏à ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÉ‡∏ô‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏£‡∏≤‡∏ö‡∏£‡∏∑‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏ô‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n(‡∏ï‡∏±‡∏î system prompt ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á‡πÑ‡∏î‡πâ)"""
        response = model.generate_content(prompt, generation_config={"temperature": 0.6, "max_output_tokens": 1024})
        return response.text
    except Exception as e:
        return f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö Gemini API: {str(e)}"

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Get user input
user_query = st.chat_input("‡∏ñ‡∏≤‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢!")

# Generate and display response
if user_query:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_query})
    # Display user message
    with st.chat_message("user"):
        st.markdown(user_query)
    # Display assistant response with spinner
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")
        # Search vector database for relevant context
        if st.session_state.vectordb:
            docs = st.session_state.vectordb.similarity_search(user_query, k=5)
            context = "\n\n".join([doc.page_content for doc in docs])
        else:
            context = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        # Generate response
        response = generate_response(user_query, context, GEMINI_API_KEY)
        message_placeholder.markdown(response)
    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response})

# Display welcome message if no messages yet
if not st.session_state.messages:
    st.info("üëã ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏ú‡∏° ‡∏°‡∏ó‡∏£.‡∏•‡πâ‡∏≤‡∏ô‡∏ô‡∏≤ ‡πÑ‡∏Å‡∏î‡πå‡πÄ‡∏à‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà (RMUTL Guide Chiang Mai) ‡∏ñ‡∏≤‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö")

# Add footer
st.markdown("---")
st.markdown("¬© 2025 RMUTL AI - ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞")