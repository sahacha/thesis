{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347aa53b",
   "metadata": {},
   "source": [
    "## ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Embedding Model\n",
    "\n",
    "### ‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:\n",
    "1. **‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà**: `combined_collection_thai` ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\n",
    "2. **Embedding Model**: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å `all-MiniLM-L6-v2` ‡πÄ‡∏õ‡πá‡∏ô `sentence-transformers/distiluse-base-multilingual-cased`\n",
    "3. **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£**: 300 ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡∏¢‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°)\n",
    "4. **Embedding Dimensions**: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 384 ‡πÄ‡∏õ‡πá‡∏ô 512 dimensions\n",
    "\n",
    "### üìà ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Embedding ‡πÉ‡∏´‡∏°‡πà:\n",
    "- **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤**: ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢  \n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô**: ‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤\n",
    "- **‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô**: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏∞‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "\n",
    "### üöÄ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:\n",
    "‡πÉ‡∏ä‡πâ `new_combined_vector_store` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞ RAG ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö Chatbot ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "generator_llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",  # Fastest, cheapest model\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048,  # LIMIT: 2048 tokens per request\n",
    "    timeout=30,      # Short timeout\n",
    "    max_retries=1,   # Fewer retries\n",
    ")\n",
    "\n",
    "# Use HuggingFace embeddings that produce 384 dimensions\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/distiluse-base-multilingual-cased\"  # This produces 384-dimensional embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe444e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å collections ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "def migrate_all_collections_to_new_embedding(target_collection_name, new_embedding_function):\n",
    "    \"\"\"\n",
    "    ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å collections ‡πÑ‡∏õ‡∏¢‡∏±‡∏á embedding ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "    \"\"\"\n",
    "    print(\"=== ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏° Collections ===\")\n",
    "\n",
    "    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        client.delete_collection(target_collection_name)\n",
    "        print(f\"‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô {target_collection_name} ‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß\")\n",
    "    except:\n",
    "        print(f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô {target_collection_name} ‡πÄ‡∏Å‡πà‡∏≤\")\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà\n",
    "    combined_vector_store = Chroma(\n",
    "        client=client,\n",
    "        collection_name=target_collection_name,\n",
    "        embedding_function=new_embedding_function,\n",
    "    )\n",
    "\n",
    "    # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢)\n",
    "    source_collections = [\"attraction\", \"hotel\", \"restaurant\"]\n",
    "\n",
    "    total_documents = 0\n",
    "    doc_counter = 0\n",
    "\n",
    "    for collection_name in source_collections:\n",
    "        try:\n",
    "            print(f\"\\\\n--- ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {collection_name} ---\")\n",
    "\n",
    "            # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\n",
    "            source_collection = client.get_collection(collection_name)\n",
    "            collection_data = source_collection.get(include=['documents', 'metadatas'])\n",
    "\n",
    "            documents = collection_data['documents']\n",
    "            metadatas = collection_data['metadatas']\n",
    "            document_count = len(documents)\n",
    "\n",
    "            print(f\"‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ {document_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô {collection_name}\")\n",
    "\n",
    "            if document_count == 0:\n",
    "                print(f\"‡∏Ç‡πâ‡∏≤‡∏° {collection_name} (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£)\")\n",
    "                continue\n",
    "\n",
    "            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡∏•‡∏∞ batch\n",
    "            batch_size = 50\n",
    "            total_batches = document_count // batch_size + (1 if document_count % batch_size > 0 else 0)\n",
    "\n",
    "            for i in range(0, document_count, batch_size):\n",
    "                batch_num = i // batch_size + 1\n",
    "                print(f\"  Batch {batch_num}/{total_batches} ‡∏Ç‡∏≠‡∏á {collection_name}\")\n",
    "\n",
    "                end_idx = min(i + batch_size, document_count)\n",
    "                batch_documents = documents[i:end_idx]\n",
    "                batch_metadatas = metadatas[i:end_idx] if metadatas else None\n",
    "\n",
    "                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Document objects ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏° source type\n",
    "                doc_objects = []\n",
    "                batch_ids = []\n",
    "\n",
    "                for j, doc_text in enumerate(batch_documents):\n",
    "                    metadata = batch_metadatas[j] if batch_metadatas else {}\n",
    "                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• source collection\n",
    "                    metadata['source_collection'] = collection_name\n",
    "\n",
    "                    doc_objects.append(Document(page_content=doc_text, metadata=metadata))\n",
    "                    batch_ids.append(f\"{collection_name}_{doc_counter}\")\n",
    "                    doc_counter += 1\n",
    "\n",
    "                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏•‡∏á‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏£‡∏ß‡∏°\n",
    "                try:\n",
    "                    combined_vector_store.add_documents(documents=doc_objects, ids=batch_ids)\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î batch {batch_num}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            total_documents += document_count\n",
    "            print(f\"‡πÄ‡∏û‡∏¥‡πà‡∏° {document_count} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å {collection_name} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö {collection_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    final_count = client.get_collection(target_collection_name).count()\n",
    "    print(f\"\\\\n=== ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ===\")\n",
    "    print(f\"‡∏£‡∏ß‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_documents} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\")\n",
    "    print(f\"‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà: {final_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£\")\n",
    "    print(f\"‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô '{target_collection_name}' ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô\")\n",
    "\n",
    "    return combined_vector_store\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏£‡∏ß‡∏°‡πÉ‡∏´‡∏°‡πà\n",
    "print(\"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á Collections ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡∏¢‡∏±‡∏á Multilingual Embedding...\")\n",
    "all_combined_vector_store = migrate_all_collections_to_new_embedding(\n",
    "    target_collection_name=\"all_collections_thai\",\n",
    "    new_embedding_function=new_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1975b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏£‡∏ß‡∏°‡πÉ‡∏´‡∏°‡πà\n",
    "test_queries_comprehensive = [\n",
    "    \"‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÉ‡∏ô‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\",\n",
    "    \"‡πÇ‡∏£‡∏á‡πÅ‡∏£‡∏°‡∏î‡∏µ‡πÜ ‡πÉ‡∏ô‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\",\n",
    "    \"‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡πÅ‡∏ó‡πâ‡πÜ\",\n",
    "    \"‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡πà‡∏≤‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß\",\n",
    "    \"‡∏ß‡∏±‡∏î‡∏™‡∏ß‡∏¢‡πÜ ‡πÉ‡∏ô‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\"\n",
    "]\n",
    "\n",
    "print(\"=== ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏£‡∏ß‡∏° (all_collections_thai) ===\")\n",
    "print(f\"Embedding: {new_embeddings.model_name}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, query in enumerate(test_queries_comprehensive, 1):\n",
    "    print(f\"\\\\n{i}. ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    results = all_combined_vector_store.similarity_search(query, k=5)\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏≤‡∏° source collection\n",
    "    source_counts = {}\n",
    "    for j, doc in enumerate(results, 1):\n",
    "        name = doc.metadata.get('name', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠')\n",
    "        source = doc.metadata.get('source_collection', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')\n",
    "        rating = doc.metadata.get('rating', 'N/A')\n",
    "\n",
    "        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏° source\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "        print(f\"  {j}. [{source.upper()}] {name}\")\n",
    "        if rating != 'N/A':\n",
    "            print(f\"      ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {rating}\")\n",
    "        print(f\"      {doc.page_content[:100]}...\")\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ source\n",
    "    print(f\"\\\\n  üìä ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {dict(source_counts)}\")\n",
    "\n",
    "print(f\"\\\\nüéâ ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™Ÿà‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô 'all_collections_thai' ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c698e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "print(\"=== ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á ===\")\n",
    "print()\n",
    "\n",
    "collections = client.list_collections()\n",
    "for collection in collections:\n",
    "    try:\n",
    "        col = client.get_collection(collection.name)\n",
    "        count = col.count()\n",
    "\n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        is_new = \"_thai\" in collection.name or collection.name == \"all_collections_thai\"\n",
    "        status = \"üÜï ‡πÉ‡∏´‡∏°‡πà (Multilingual)\" if is_new else \"üìÑ ‡πÄ‡∏î‡∏¥‡∏°\"\n",
    "\n",
    "        print(f\"{status} {collection.name}: {count:,} documents\")\n",
    "\n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á metadata ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà\n",
    "        if is_new and count > 0:\n",
    "            sample = col.get(limit=1, include=['metadatas'])\n",
    "            if sample['metadatas']:\n",
    "                print(f\"   üìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á metadata: {list(sample['metadatas'][0].keys())}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {collection.name}: Error - {e}\")\n",
    "\n",
    "print(f\"\\\\n=== ‡∏™‡∏£‡∏∏‡∏õ ===\")\n",
    "print(f\"‚úÖ ‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å: 'all_collections_thai'\")\n",
    "print(f\"üî§ Embedding Model: sentence-transformers/distiluse-base-multilingual-cased\")\n",
    "print(f\"üåê ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ\")\n",
    "print(f\"üìä ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å 3 ‡πÅ‡∏´‡∏•‡πà‡∏á: attractions, hotels, restaurants\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
