{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347aa53b",
   "metadata": {},
   "source": [
    "## à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ Embedding Model\n",
    "\n",
    "### âœ… à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¹„à¸”à¹‰:\n",
    "1. **à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹ƒà¸«à¸¡à¹ˆ**: `combined_collection_thai` à¸–à¸¹à¸à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¸¶à¹‰à¸™à¸ªà¸³à¹€à¸£à¹‡à¸ˆ\n",
    "2. **Embedding Model**: à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸ˆà¸²à¸ `all-MiniLM-L6-v2` à¹€à¸›à¹‡à¸™ `sentence-transformers/distiluse-base-multilingual-cased`\n",
    "3. **à¸ˆà¸³à¸™à¸§à¸™à¹€à¸­à¸à¸ªà¸²à¸£**: 300 à¹€à¸­à¸à¸ªà¸²à¸£ (à¸¢à¹‰à¸²à¸¢à¸¡à¸²à¸ˆà¸²à¸à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹€à¸”à¸´à¸¡)\n",
    "4. **Embedding Dimensions**: à¹€à¸à¸´à¹ˆà¸¡à¸ˆà¸²à¸ 384 à¹€à¸›à¹‡à¸™ 512 dimensions\n",
    "\n",
    "### ğŸ“ˆ à¸‚à¹‰à¸­à¸”à¸µà¸‚à¸­à¸‡ Embedding à¹ƒà¸«à¸¡à¹ˆ:\n",
    "- **à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸”à¸µà¸à¸§à¹ˆà¸²**: à¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¸ªà¸³à¸«à¸£à¸±à¸šà¸«à¸¥à¸²à¸¢à¸ à¸²à¸©à¸²à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢  \n",
    "- **à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸ªà¸¹à¸‡à¸‚à¸¶à¹‰à¸™**: à¸ˆà¸±à¸šà¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡à¸„à¸³à¹à¸¥à¸°à¸›à¸£à¸°à¹‚à¸¢à¸„à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹„à¸”à¹‰à¸”à¸µà¸à¸§à¹ˆà¸²\n",
    "- **à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸—à¸µà¹ˆà¸”à¸µà¸‚à¸¶à¹‰à¸™**: à¸œà¸¥à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¸ˆà¸°à¸•à¸£à¸‡à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™\n",
    "\n",
    "### ğŸš€ à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸•à¹ˆà¸­à¹„à¸›:\n",
    "à¹ƒà¸Šà¹‰ `new_combined_vector_store` à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹à¸¥à¸° RAG à¹ƒà¸™à¸£à¸°à¸šà¸š Chatbot à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "generator_llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",  # Fastest, cheapest model\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048,  # LIMIT: 2048 tokens per request\n",
    "    timeout=30,      # Short timeout\n",
    "    max_retries=1,   # Fewer retries\n",
    ")\n",
    "\n",
    "# Use HuggingFace embeddings that produce 384 dimensions\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/distiluse-base-multilingual-cased\"  # This produces 384-dimensional embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe444e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸›à¸¥à¸‡à¸—à¸¸à¸ collections à¹à¸¥à¸°à¸£à¸§à¸¡à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™\n",
    "def migrate_all_collections_to_new_embedding(target_collection_name, new_embedding_function):\n",
    "    \"\"\"\n",
    "    à¹à¸›à¸¥à¸‡à¸—à¸¸à¸ collections à¹„à¸›à¸¢à¸±à¸‡ embedding à¹ƒà¸«à¸¡à¹ˆà¹à¸¥à¸°à¸£à¸§à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹€à¸”à¸µà¸¢à¸§\n",
    "    \"\"\"\n",
    "    print(\"=== à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¹à¸›à¸¥à¸‡à¹à¸¥à¸°à¸£à¸§à¸¡ Collections ===\")\n",
    "\n",
    "    # à¸¥à¸šà¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸–à¹‰à¸²à¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§\n",
    "    try:\n",
    "        client.delete_collection(target_collection_name)\n",
    "        print(f\"à¸¥à¸šà¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™ {target_collection_name} à¹€à¸à¹ˆà¸²à¹à¸¥à¹‰à¸§\")\n",
    "    except:\n",
    "        print(f\"à¹„à¸¡à¹ˆà¸à¸šà¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™ {target_collection_name} à¹€à¸à¹ˆà¸²\")\n",
    "\n",
    "    # à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹ƒà¸«à¸¡à¹ˆ\n",
    "    combined_vector_store = Chroma(\n",
    "        client=client,\n",
    "        collection_name=target_collection_name,\n",
    "        embedding_function=new_embedding_function,\n",
    "    )\n",
    "\n",
    "    # à¸£à¸²à¸¢à¸à¸²à¸£à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸›à¸¥à¸‡ (à¸¢à¸à¹€à¸§à¹‰à¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢)\n",
    "    source_collections = [\"attraction\", \"hotel\", \"restaurant\"]\n",
    "\n",
    "    total_documents = 0\n",
    "    doc_counter = 0\n",
    "\n",
    "    for collection_name in source_collections:\n",
    "        try:\n",
    "            print(f\"\\\\n--- à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ {collection_name} ---\")\n",
    "\n",
    "            # à¸”à¸¶à¸‡à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š\n",
    "            source_collection = client.get_collection(collection_name)\n",
    "            collection_data = source_collection.get(include=['documents', 'metadatas'])\n",
    "\n",
    "            documents = collection_data['documents']\n",
    "            metadatas = collection_data['metadatas']\n",
    "            document_count = len(documents)\n",
    "\n",
    "            print(f\"à¸à¸šà¹€à¸­à¸à¸ªà¸²à¸£ {document_count} à¸£à¸²à¸¢à¸à¸²à¸£à¹ƒà¸™ {collection_name}\")\n",
    "\n",
    "            if document_count == 0:\n",
    "                print(f\"à¸‚à¹‰à¸²à¸¡ {collection_name} (à¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸­à¸à¸ªà¸²à¸£)\")\n",
    "                continue\n",
    "\n",
    "            # à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¸¥à¸° batch\n",
    "            batch_size = 50\n",
    "            total_batches = document_count // batch_size + (1 if document_count % batch_size > 0 else 0)\n",
    "\n",
    "            for i in range(0, document_count, batch_size):\n",
    "                batch_num = i // batch_size + 1\n",
    "                print(f\"  Batch {batch_num}/{total_batches} à¸‚à¸­à¸‡ {collection_name}\")\n",
    "\n",
    "                end_idx = min(i + batch_size, document_count)\n",
    "                batch_documents = documents[i:end_idx]\n",
    "                batch_metadatas = metadatas[i:end_idx] if metadatas else None\n",
    "\n",
    "                # à¸ªà¸£à¹‰à¸²à¸‡ Document objects à¸à¸£à¹‰à¸­à¸¡à¹€à¸à¸´à¹ˆà¸¡ source type\n",
    "                doc_objects = []\n",
    "                batch_ids = []\n",
    "\n",
    "                for j, doc_text in enumerate(batch_documents):\n",
    "                    metadata = batch_metadatas[j] if batch_metadatas else {}\n",
    "                    # à¹€à¸à¸´à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ source collection\n",
    "                    metadata['source_collection'] = collection_name\n",
    "\n",
    "                    doc_objects.append(Document(page_content=doc_text, metadata=metadata))\n",
    "                    batch_ids.append(f\"{collection_name}_{doc_counter}\")\n",
    "                    doc_counter += 1\n",
    "\n",
    "                # à¹€à¸à¸´à¹ˆà¸¡à¹€à¸­à¸à¸ªà¸²à¸£à¸¥à¸‡à¹ƒà¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸£à¸§à¸¡\n",
    "                try:\n",
    "                    combined_vector_store.add_documents(documents=doc_objects, ids=batch_ids)\n",
    "                except Exception as e:\n",
    "                    print(f\"    à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸” batch {batch_num}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            total_documents += document_count\n",
    "            print(f\"à¹€à¸à¸´à¹ˆà¸¡ {document_count} à¹€à¸­à¸à¸ªà¸²à¸£à¸ˆà¸²à¸ {collection_name} à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¸à¸±à¸š {collection_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ\n",
    "    final_count = client.get_collection(target_collection_name).count()\n",
    "    print(f\"\\\\n=== à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ ===\")\n",
    "    print(f\"à¸£à¸§à¸¡à¹€à¸­à¸à¸ªà¸²à¸£à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {total_documents} à¸£à¸²à¸¢à¸à¸²à¸£\")\n",
    "    print(f\"à¹€à¸­à¸à¸ªà¸²à¸£à¹ƒà¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹ƒà¸«à¸¡à¹ˆ: {final_count} à¸£à¸²à¸¢à¸à¸²à¸£\")\n",
    "    print(f\"à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™ '{target_collection_name}' à¸ªà¸£à¹‰à¸²à¸‡à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™\")\n",
    "\n",
    "    return combined_vector_store\n",
    "\n",
    "# à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹€à¸à¸·à¹ˆà¸­à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸£à¸§à¸¡à¹ƒà¸«à¸¡à¹ˆ\n",
    "print(\"à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¹à¸›à¸¥à¸‡ Collections à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹„à¸›à¸¢à¸±à¸‡ Multilingual Embedding...\")\n",
    "all_combined_vector_store = migrate_all_collections_to_new_embedding(\n",
    "    target_collection_name=\"all_collections_thai\",\n",
    "    new_embedding_function=new_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1975b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹ƒà¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸£à¸§à¸¡à¹ƒà¸«à¸¡à¹ˆ\n",
    "test_queries_comprehensive = [\n",
    "    \"à¹à¸™à¸°à¸™à¸³à¸ªà¸–à¸²à¸™à¸—à¸µà¹ˆà¸—à¹ˆà¸­à¸‡à¹€à¸—à¸µà¹ˆà¸¢à¸§à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´à¹ƒà¸™à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ\",\n",
    "    \"à¹‚à¸£à¸‡à¹à¸£à¸¡à¸”à¸µà¹† à¹ƒà¸™à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ\",\n",
    "    \"à¸£à¹‰à¸²à¸™à¸­à¸²à¸«à¸²à¸£à¹€à¸«à¸™à¸·à¸­à¹à¸—à¹‰à¹†\",\n",
    "    \"à¸•à¸¥à¸²à¸”à¸™à¹ˆà¸²à¹€à¸—à¸µà¹ˆà¸¢à¸§\",\n",
    "    \"à¸§à¸±à¸”à¸ªà¸§à¸¢à¹† à¹ƒà¸™à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ\"\n",
    "]\n",
    "\n",
    "print(\"=== à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹ƒà¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸£à¸§à¸¡ (all_collections_thai) ===\")\n",
    "print(f\"Embedding: {new_embeddings.model_name}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, query in enumerate(test_queries_comprehensive, 1):\n",
    "    print(f\"\\\\n{i}. à¸„à¸³à¸–à¸²à¸¡: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # à¸„à¹‰à¸™à¸«à¸²à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ\n",
    "    results = all_combined_vector_store.similarity_search(query, k=5)\n",
    "\n",
    "    # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸ˆà¸³à¹à¸™à¸à¸•à¸²à¸¡ source collection\n",
    "    source_counts = {}\n",
    "    for j, doc in enumerate(results, 1):\n",
    "        name = doc.metadata.get('name', 'à¹„à¸¡à¹ˆà¸¡à¸µà¸Šà¸·à¹ˆà¸­')\n",
    "        source = doc.metadata.get('source_collection', 'à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸')\n",
    "        rating = doc.metadata.get('rating', 'N/A')\n",
    "\n",
    "        # à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¸•à¸²à¸¡ source\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "        print(f\"  {j}. [{source.upper()}] {name}\")\n",
    "        if rating != 'N/A':\n",
    "            print(f\"      à¸„à¸°à¹à¸™à¸™: {rating}\")\n",
    "        print(f\"      {doc.page_content[:100]}...\")\n",
    "\n",
    "    # à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´ source\n",
    "    print(f\"\\\\n  ğŸ“Š à¹à¸«à¸¥à¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {dict(source_counts)}\")\n",
    "\n",
    "print(f\"\\\\nğŸ‰ à¸à¸²à¸£à¸—à¸”à¸ªÙˆà¸šà¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™! à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™ 'all_collections_thai' à¸à¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c698e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ªà¸–à¸²à¸™à¸°à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢\n",
    "print(\"=== à¸ªà¸–à¸²à¸™à¸°à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸«à¸¥à¸±à¸‡à¸à¸²à¸£à¹à¸›à¸¥à¸‡ ===\")\n",
    "print()\n",
    "\n",
    "collections = client.list_collections()\n",
    "for collection in collections:\n",
    "    try:\n",
    "        col = client.get_collection(collection.name)\n",
    "        count = col.count()\n",
    "\n",
    "        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹ƒà¸«à¸¡à¹ˆà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ\n",
    "        is_new = \"_thai\" in collection.name or collection.name == \"all_collections_thai\"\n",
    "        status = \"ğŸ†• à¹ƒà¸«à¸¡à¹ˆ (Multilingual)\" if is_new else \"ğŸ“„ à¹€à¸”à¸´à¸¡\"\n",
    "\n",
    "        print(f\"{status} {collection.name}: {count:,} documents\")\n",
    "\n",
    "        # à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ metadata à¸‚à¸­à¸‡à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¹ƒà¸«à¸¡à¹ˆ\n",
    "        if is_new and count > 0:\n",
    "            sample = col.get(limit=1, include=['metadatas'])\n",
    "            if sample['metadatas']:\n",
    "                print(f\"   ğŸ“‹ à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ metadata: {list(sample['metadatas'][0].keys())}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {collection.name}: Error - {e}\")\n",
    "\n",
    "print(f\"\\\\n=== à¸ªà¸£à¸¸à¸› ===\")\n",
    "print(f\"âœ… à¸„à¸­à¸¥à¹€à¸¥à¸à¸Šà¸±à¸™à¸«à¸¥à¸±à¸: 'all_collections_thai'\")\n",
    "print(f\"ğŸ”¤ Embedding Model: sentence-transformers/distiluse-base-multilingual-cased\")\n",
    "print(f\"ğŸŒ à¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹„à¸”à¹‰à¸”à¸µ\")\n",
    "print(f\"ğŸ“Š à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ 3 à¹à¸«à¸¥à¹ˆà¸‡: attractions, hotels, restaurants\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
